{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Data Science  \n",
    "DATA20047 Probabilistic Cognitive Modelling - Spring 2025  \n",
    "Luigi Acerbi  \n",
    "\n",
    "# Problem Set 4: Combining inference with utility, and everything\n",
    "\n",
    "- This homework problem set focuses on **Week 7** of the course, plus a recap of everything we have done in the course.\n",
    "- This problem set is worth **30 points** in total (out of 100 for the full course).\n",
    "- Check the submission deadline on Moodle! **Note that the deadline is just before midnight.**\n",
    "\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "Submission must be perfomed entirely on Moodle (**not** by email).\n",
    "1. When you have completed the exercises, save the notebook.\n",
    "2. Report your solutions and answers on Moodle (\"*Problem set 4 answer return*\").\n",
    "3. Submit two files on Moodle (\"*Problem set 4 notebook return*\"): \n",
    "  - The notebook as `.ipynb`.\n",
    "  - The same notebook downloaded as `.pdf.\n",
    "\n",
    "#### How to save the notebook as PDF\n",
    "\n",
    "There are various ways to save the Jupyter notebook as PDF, depending on the version of Jupyter notebook you have.\n",
    "\n",
    "- In older versions, you should be able to select \"File\" > \"Print Preview\" and then print the page to PDF using your browser (remember to enter the Print Preview first).\n",
    "- In more recent versions, you can select \"File\" > \"Save and Export Notebook As\" > \"PDF\".\n",
    "  * For this to work, you may need to install [Pandoc](https://pandoc.org/installing.html) first.\n",
    "  * Compiling to PDF might take a while.\n",
    "\n",
    "## IMPORTANT\n",
    "\n",
    "1. Do not share your code and answers with others. Contrary to the class exercises, which you can do with others, these problems are *not* group work and must be done individually.\n",
    "2. It is allowed to use snippets of code from the lecture exercises and model solutions.\n",
    "3. It is your responsibility to ensure that the notebook has fully finished running all the cells, all the plots view properly etc. before submitting it. However, the notebook should be runnable from scratch if needed (\"Kernel > Restart & Run All\").\n",
    "4. Submit your work by the deadline.\n",
    "5. Unless stated otherwise, please report your numerical answers in Moodle with full numerical precision (~14-15 digits), unless the answer is an integer.\n",
    "6. If you are confused, think there is a mistake or find things too difficult, please ask on Moodle.\n",
    "\n",
    "## References\n",
    "\n",
    "- \\[**MKG23**\\] Ma WJ, KÃ¶rding K, and Goldreich D. \"Bayesian Models of Perception and Action: An Introduction\". MIT Press, 2023.\n",
    "- \\[**AWV12**\\] Acerbi L, Wolpert DM, Vijayakumar S. \"Internal Representations of Temporal Statistics and Feedback Calibrate Motor-Sensory Interval Timing\". *PLoS Computational Biology*, 2012. [Link](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.1 (6 pts)\n",
    "\n",
    "> In this question, we will look at the optimal aim location when playing a modified game of darts.\n",
    "\n",
    "Assume you are playing a game of darts, that is you need to throw a dart at a target a couple of meters away from you. For simplicity, we assume this is a modified version of the game in which the target board comprises of a series of vertical bands, so that only the horizontal landing location of the dart matters. Landing the dart on each different sector is associated with a different score.\n",
    "\n",
    "We measure horizontal location starting from the center of the dart board ($0$ cm), with negative numbers meaning a position to the left of the center and positive numbers a position to the right of the center. We ignore the vertical position, assuming the bands are tall enough to be easy to hit on the vertical axis.\n",
    "\n",
    "The sectors are characterized by their bounds on the board (start and end location) and their score, as follows:\n",
    "\n",
    "- -25 to -15 cm: 15 points.\n",
    "- -15 to -5 cm: 10 points.\n",
    "- -5 to 5 cm: 20 points.\n",
    "- 5 to 15 cm: 5 points.\n",
    "- 15 to 25 cm: 25 points.\n",
    "\n",
    "If the dart lands outside the board, you would get 0 points.\n",
    "\n",
    "Given the aim location $\\hat{s}$, we assume that due to motor noise, the actual *hit* location $r$ (where the dart actually lands) is distributed as follows:\n",
    "$$\n",
    "p(r|\\hat{s}) = (1-\\lambda) \\mathcal{N}\\left(r; \\hat{s},\\sigma^2_\\text{motor}\\right) + \\lambda \\mathcal{N}\\left(r; \\hat{s},\\sigma^2_\\text{lapse}\\right),\n",
    "$$\n",
    "where $\\sigma_\\text{motor}$ is the standard spread location due to motor error and throwing variability. The novelty of this equation is that we also consider a probability $\\lambda \\in [0, 1]$ of lapsing (e.g., sneezing or being distracted by a friend while throwing), which produces a bad throw with a larger error $\\sigma_\\text{lapse}$. For this exercise, we assume $\\sigma_\\text{lapse} = 20$ cm.\n",
    "\n",
    "Write a function that computes the expected score as a function of aim location $\\hat{s}$ and task parameters $\\left(\\sigma_\\text{motor}, \\lambda, \\sigma_\\text{lapse}\\right)$. Then, write a function that for given task parameters $\\left(\\sigma_\\text{motor}, \\lambda, \\sigma_\\text{lapse}\\right)$, returns the optimal aim location $s^\\star$ (the aim point which produces the maximum expected score).\n",
    "\n",
    "- a) For $\\sigma_\\text{motor} \\in [2, 10]$ cm and $\\lambda \\in [0, 0.2]$, what are the rightmost (maximum) and leftmost (minimum) locations for $s^\\star$?\n",
    "- b) For $\\lambda = 0.1$, plot $s^\\star$ as a function of $\\sigma_\\text{motor}$, for $\\sigma_\\text{motor} \\in [2, 10]$ cm. You should see an interesting switch of optimal strategy. Around which value of $\\sigma_\\text{motor}$ the optimal strategy switches and it becomes more convenient to throw the dart to the left of the center as opposed to the right of the center?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bands = [-np.inf,-25,-15,-5,5,15,25,np.inf]\n",
    "scores = [0,15,10,20,5,25,0]\n",
    "\n",
    "# Plot target score\n",
    "\n",
    "s = np.linspace(-30,30,200)\n",
    "for index, band in enumerate(scores):\n",
    "    a = np.maximum(bands[index], -40)\n",
    "    b = np.minimum(bands[index+1], 40)\n",
    "    plt.plot((a,a,b,b),np.array((0,scores[index],scores[index],0)))\n",
    "\n",
    "plt.xlabel('r (cm)')\n",
    "plt.ylabel('score (points)')\n",
    "plt.title('Target score based on landing point')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum s_star: -1.9769769769769745\n",
      "maximum s_star: 19.894894894894897\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strategy switches at sigma_motor â 7.077077077077077\n"
     ]
    }
   ],
   "source": [
    "sigma_lapse = 20\n",
    "\n",
    "def get_score(r):\n",
    "\taux = np.zeros_like(r)\n",
    "\tfor index, band in enumerate(scores):\n",
    "\t\taux[(r >= bands[index]) & (r <= bands[index + 1])] = scores[index]\n",
    "\treturn aux\n",
    "\n",
    "def expected_score(s_hat, sigma_motor, lambda_param):\n",
    "    Nr = 2**10+1\n",
    "    lower_bound = -30\n",
    "    upper_bound = 30\n",
    "    r = np.linspace(lower_bound, upper_bound, Nr)\n",
    "    scores = get_score(r)\n",
    "    \n",
    "    posterior = (1 - lambda_param) * sps.norm.pdf(r.reshape(-1, 1), s_hat, sigma_motor) + \\\n",
    "          lambda_param * sps.norm.pdf(r.reshape(-1, 1), s_hat, sigma_lapse)\n",
    "    \n",
    "    dx = r[1] - r[0]\n",
    "    return sp.integrate.romb(scores.reshape(-1, 1) * posterior, dx=dx, axis=0)\n",
    "\n",
    "def find_optimal_aim(sigma_motor, lambda_param):\n",
    "    aim_points = np.linspace(-25, 25, 1000)\n",
    "    scores = expected_score(aim_points, sigma_motor, lambda_param)\n",
    "    return aim_points[np.argmax(scores)]\n",
    "\n",
    "sigma_motor_range = np.linspace(2, 10, 500)\n",
    "lambda_range = np.linspace(0, 0.2, 5)\n",
    "\n",
    "optimal_aim_range = np.array([find_optimal_aim(sigma, lambda_) for sigma in sigma_motor_range for lambda_ in lambda_range])\n",
    "min_s_star = np.min(optimal_aim_range)\n",
    "max_s_star = np.max(optimal_aim_range)\n",
    "print(f\"minimum s_star: {min_s_star}\")\n",
    "print(f\"maximum s_star: {max_s_star}\")\n",
    "\n",
    "lambda_fixed = 0.1\n",
    "s_star_values = np.array([find_optimal_aim(sigma, lambda_fixed) for sigma in sigma_motor_range])\n",
    "\n",
    "plt.plot(sigma_motor_range, s_star_values)\n",
    "plt.xlabel(\"sigma_motor\")\n",
    "plt.ylabel(\"s_star\")\n",
    "plt.title(\"s_star vs sigma_motor (lambda_fixed = 0.1)\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "switch_index = np.where(np.diff(np.sign(s_star_values)))[0]\n",
    "if switch_index.size > 0:\n",
    "    switch_value = sigma_motor_range[switch_index[0]]\n",
    "    print(f\"strategy switches at sigma_motor â {switch_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.2 (6 pts)\n",
    "\n",
    "> In this question, we will infer the empirical loss function of an observer in a task based on their responses.\n",
    "\n",
    "In each trial of this experiment, the participant is shown a cloud of dots on a screen. The horizontal location of each dot is drawn from the following mixture distribution:\n",
    "  $$\n",
    "  p(s; h) = 0.8 \\mathcal{N}\\left(s; 0, 0.2^2\\right) + 0.2 \\mathcal{N}\\left(s; h, 0.2^2\\right)\n",
    "  $$\n",
    "  where $h$ is a parameter controlled by the experimenter, and is changed from trial to trial. The horizontal location is measured in normalized screen units $s \\in [-1, 1]$, where $0$ is the center of the screen. \n",
    "- Along the vertical axis, the dots show a small jitter along the center of the screen (we ignore the vertical displacement).\n",
    "- In each trial, the subject is asked to report the horizontal position of the *center* of the cloud of dots. The word \"center\" is ambiguous, as we could be asking for the mean, the median, or other [measures of central tendency](https://en.wikipedia.org/wiki/Central_tendency). The question is what the subject would naturally report. We assume the subject reports the estimate $\\hat{s}$ that minimizes their expected loss. \n",
    "- For the purpose of this question, we also assume that the observer's loss function takes the parametric form\n",
    "  $$\n",
    "  \\mathcal{L}_\\alpha\\left(s^\\prime, s \\right) = \\left| s^\\prime - s \\right|^\\alpha\n",
    "  $$\n",
    "  which is the loss for reporting $s^\\prime$ for a dot position $s$. \n",
    "- In each trial, the expected loss is the expectation of the loss over the presented dot locations, $p(s; h)$.\n",
    "- A sequence of trials is thus represented by the trial design (the presented distribution of dots, parameterized by $h_t$) and the observer's responses $\\hat{s}_t$ in each trial $t$.\n",
    "- For simplicity, here we assume that there is no response noise.\n",
    "\n",
    "------------------\n",
    "\n",
    "- a) First, as a sanity check, compute the *expected loss* assuming $\\alpha = 1$, a fixed value of $h = 0.3$ and a candidate estimate $s^\\prime = 0.5$. In formulas:\n",
    "$$\n",
    "\\mathbb{E}\\left[ \\mathcal{L}_\\alpha\\left(s^\\prime, s \\right) \\right] = \\int p(s; h) \\mathcal{L}_\\alpha\\left(s^\\prime, s \\right) ds\n",
    "$$\n",
    "  where you should replace the pdf and the loss with the definitions provided in the text of the exercise.\n",
    "  Report the expected loss for this specific case in Moodle.\n",
    "- b) Now, as a further sanity check, for same case $\\alpha = 1$ and $h = 0.3$, report the *optimal estimate*, that is the estimate $s^\\star$ that minimizes the expected loss. In formulas:\n",
    "$$\n",
    "s^\\star = \\arg\\min_{s^\\prime} \\mathbb{E}\\left[ \\mathcal{L}_\\alpha\\left(s^\\prime, s \\right) \\right]\n",
    "$$\n",
    "  Report the optimal estimate for this specific case in Moodle.\n",
    "- c) Given the data reported below, infer the exponent $\\alpha \\ge 0$ of the loss function that best describes the subject behavior. Do so by finding the $\\alpha$ that minimizes the total squared error between the model predictions (assuming the observer follows Bayesian decision theory) and the data, summed over trials. Report the best estimate for $\\alpha$ in Moodle (error tolerance $\\pm 0.1$).\n",
    "\n",
    "*Notes*: \n",
    "- Assume that the horizontal location $s \\in [-1, 1]$ (i.e., within the width of the screen).\n",
    "- In real data, the observer's responses would be corrupted by decision and motor noise, which would make inferring the loss function still more complex. For example, it would be better to use Bayesian inference to infer a posterior over $\\alpha$, as opposed to a point estimate. Still, the logic would be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For part c - trial parameters h_t and subject's responses s_hat_t\n",
    "\n",
    "h_t = np.array([-0.0663824 ,  0.17625959, -0.3999085 , -0.15813394, -0.28259529,\n",
    "       -0.32612912, -0.25099183, -0.12355142, -0.08258602,  0.03105339,\n",
    "       -0.06464439,  0.1481756 , -0.2364382 ,  0.30249395, -0.37808993,\n",
    "        0.13637401, -0.06615616,  0.04695186, -0.28769045, -0.24151881])\n",
    "s_hat_t = np.array([-0.0125   ,  0.034375 , -0.0734375, -0.03125  , -0.0546875,\n",
    "       -0.0609375, -0.0484375, -0.025    , -0.0171875,  0.00625  ,\n",
    "       -0.0125   ,  0.0296875, -0.0453125,  0.0578125, -0.0703125,\n",
    "        0.0265625, -0.0125   ,  0.009375 , -0.0546875, -0.046875 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part a)\n",
      "[0.44728048]\n",
      "part b)\n",
      "0.05029296875\n",
      "part c)\n",
      "best estimated alpha: 1.696969696969697\n"
     ]
    }
   ],
   "source": [
    "Ns = 2**12+1\n",
    "lower_bound = -1\n",
    "upper_bound = 1\n",
    "s_grid = np.linspace(start = lower_bound, stop = upper_bound, num = Ns)\n",
    "s_prime_grid = np.linspace(start = lower_bound, stop = upper_bound, num = Ns)\n",
    "\n",
    "h = 0.3\n",
    "s_prime_fixed = 0.5\n",
    "alpha = 1\n",
    "\n",
    "\n",
    "def loss_function(s_prime, s, alpha):\n",
    "\ts_prime = np.atleast_1d(s_prime)[:, np.newaxis]  # Convert s_prime to a column vector\n",
    "\ts = np.asarray(s)\n",
    "\treturn np.abs(s_prime - s) ** alpha\n",
    "\n",
    "def expected_loss(s_prime, s, h, alpha):\n",
    "\tprior = 0.8 * sps.norm.pdf(s, 0, 0.2) + 0.2 * sps.norm.pdf(s, h, 0.2)\n",
    "\tintegrand = loss_function(s_prime = s_prime, s = s, alpha = alpha) * prior\n",
    "\tds = s.flatten()[1] - s.flatten()[0]\n",
    "\treturn sp.integrate.romb(integrand, dx = ds)\n",
    "\n",
    "def optimal_estimate(s_candidates, h, alpha):\n",
    "\tlosses = expected_loss(s_prime_grid, s_grid, h, alpha)\n",
    "\treturn s_candidates[np.argmin(losses)] \n",
    "\n",
    "alpha_candidates = np.linspace(0, 2, 100)\n",
    "errors = []\n",
    "\n",
    "print(\"part a)\")\n",
    "print(expected_loss(s_prime_fixed, s_grid, h = 0.3, alpha = 1))\n",
    "\n",
    "print(\"part b)\")\n",
    "print(s_grid[ np.argmin(expected_loss(s_prime_grid, s_grid, h, alpha)) ])\n",
    "\n",
    "for alpha in alpha_candidates:\n",
    "\ts_star_values = np.array([optimal_estimate(s_prime_grid, h, alpha) for h in h_t])\n",
    "\terror = np.sum((s_star_values - s_hat_t) ** 2)\n",
    "\terrors.append(error)\n",
    "\n",
    "print(\"part c)\")\n",
    "best_alpha = alpha_candidates[np.argmin(errors)]\n",
    "print(f\"best estimated alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.3 (18 pts)\n",
    "\n",
    "> For this question, which amounts to a small modelling and model fitting project, we will put together several topics seen in the course. Using the data of the sensorimotor timing experiment \\[**AWV12**\\] that we encountered several times in this course, we will use a Bayesian observer model to recover the observer's prior from their responses.\n",
    "\n",
    "We analyze the data with the `gaussianmixobserverwithlapse` model, defines as follows:\n",
    "\n",
    "- We assume the observer builds a (mismatched) Gaussian prior with two components:\n",
    "  $$p(s) = w_\\text{prior} \\mathcal{N}\\left(s| \\mu_{\\text{prior}}, \\sigma_{\\text{prior}, 1}^2 \\right) + \n",
    "  \\left(1 - w_\\text{prior} \\right)\\mathcal{N}\\left(s| \\mu_{\\text{prior}}, \\sigma_{\\text{prior}, 2}^2 \\right)$$ \n",
    "  over the stimuli (time intervals). We assume the two components have the same mean $\\mu_\\text{prior}$, but different weights ($w_\\text{prior}$ and $1 - w_\\text{prior}$) and standard deviations ($\\sigma_{\\text{prior}, 1}$ and $\\sigma_{\\text{prior}, 2}$).\n",
    "- We assume that the measurement distribution and likelihood are also Gaussian, $p(x|s) = \\mathcal{N}\\left(x| s, \\sigma^2 \\right)$.\n",
    "- The observer uses the *posterior mean* estimator for the value of the stimulus, $\\hat{s}_\\text{PM}$.\n",
    "- Gaussian motor response noise is added to the estimate, $p(r|\\hat{s}) = \\mathcal{N}\\left(r| \\hat{s}, \\sigma_\\text{motor}^2 \\right)$. For this exercise, we assume that $\\sigma_\\text{motor} = 70$ ms for all subjects.\n",
    "- In each trial, the observer lapses with probability $\\lambda$ (the *lapse rate*), in which case the response is drawn from $p_\\text{lapse}(r) = \\text{Uniform}\\left(r; 0, 1500 \\right)$ ms. Otherwise, the observer responds normally (according to $p(r|\\hat{s})$ described above) with probability $1 - \\lambda$. \n",
    "- The free parameters of this model are $\\mathbf{\\theta} = \\left(\\sigma, \\lambda, w_\\text{prior}, \\mu_\\text{prior}, \\sigma_{\\text{prior}, 1}, \\sigma_{\\text{prior}, 2} \\right)$.\n",
    "\n",
    "Note that the parameters $w_\\text{prior}, \\mu_\\text{prior}, \\sigma_{\\text{prior}, 1}, \\sigma_{\\text{prior,2}}$ model the subject's prior. In other words, we can use the estimates of these parameters to visualize what the subject's prior might look like.\n",
    "\n",
    "-----------------------------------------------\n",
    "\n",
    "For this analysis, we will separately consider all subjects, but for all subjects' datasets we will discard the first session, to ensure that subjects have achieved enough training in the task. We provide below example code that retrieves the stimuli $\\mathbf{s}$ and responses $\\mathbf{r}$ for a subject, withouth the first session.\n",
    "\n",
    "- a) As a sanity check, compute the log-likelihood of model parameter $\\theta_\\star = \\left(\\sigma = 100, \\lambda = 0.01, w_\\text{prior} = 0.5, \\mu_\\text{prior} = 787, \\sigma_{\\text{prior}, 1} = 100, \\sigma_{\\text{prior}, 2} = 120 \\right)$ for the dataset of subject 5 (having removed the first session) and report the result in Moodle.\n",
    "- b) Separately fit the `gaussianmixobserverwithlapse` model to all the six subjects' datasets (removing the first session from all data) via maximum-likelihood estimation. For each subject, report the maximum log-likelihood value in Moodle.\n",
    "- c) Consider now the `idealgaussianobserverwithlapse` observer model. The `idealgaussianobserverwithlapse` is the same as the model above with the difference that the observer's prior is a single Gaussian $p(s) = \\mathcal{N}\\left(s | \\mu_\\text{prior}, \\sigma^2_\\text{prior} \\right)$ with $\\mu_\\text{prior} = 787.5$ ms and $\\sigma_{\\text{prior}} = 128.1$ ms. As above, we fix $\\sigma_\\text{motor} = 70$ ms. The `idealgaussianobserverwithlapse`  model has two free parameters, $\\theta = \\left(\\sigma, \\lambda \\right)$. As a sanity check, compute the log-likelihood of model parameter $\\theta_\\star = \\left(\\sigma = 100, \\lambda = 0.01\\right)$ for the dataset of subject 5 (having removed the first session) and report the result in Moodle.\n",
    "- d) Separately fit the `idealgaussianobserverwithlapse` model to all the six subjects' datasets (removing the first session from all data) via maximum-likelihood estimation.  For each dataset, separately compute the AIC and BIC for the two models `gaussianmixobserverwithlapse` and `idealgaussianobserverwithlapse`. Sum the AIC and BIC values across subjects to find the sum AIC (or BIC) of the two models. Report the summed AIC (and BIC) for the two models separately in Moodle.\n",
    "- e) Which model is best, according to the metrics, and why do you think it is the case? Discuss your findings (max 300 words).\n",
    "\n",
    "*Hints*:\n",
    "- Both in parts (a) and (c), the log-likelihoods that you find should be between $-6000$ and $-5800$.\n",
    "- There is an analytical solution for the posterior (and $\\hat{s}_\\text{PM}$), but there is no analytical solution for the response distribution $p(r|s)$, so you will need to use numerical integration at least to compute the response distribution.\n",
    "- Finding the maximum-likelihood solution can be difficult as the optimization landscape is nontrivial. As a sanity check, verify that your solutions are consistent across different runs. If not, you might need to run additional optimization runs to increase the chance of finding the global optimum - possibly of the order of ten or even more.\n",
    "- Beware that running multiple optimizations for all subjects will take quite some time (easily 30-60 minutes overall, possibly more - depending on your code, your computer, and how many runs you do). Model fitting is time consuming!\n",
    "- Remember that you can ask questions in the Moodle discussion forum if you need further hints.\n",
    "- For this problem, you are given unlimited attempts in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data of Experiment 3 of [AWV12] from .csv file to a Pandas dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lacerbi/prob-cog-mod-files/main/data/awv12_exp3.csv')\n",
    "\n",
    "# Remove unused columns\n",
    "df.drop(df.columns[[6, 7, 8]], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with NaNs\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Example code to take the data of subject 1, excluding the first session\n",
    "subject = 1\n",
    "s = np.array(df['Stimulus (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])\n",
    "r = np.array(df['Response (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_motor = 70\n",
    "\n",
    "def gaussian_response(s,theta):\n",
    "\t\"\"\"Compute mean and standard deviation of p(r|s; theta).\"\"\"\n",
    "\t# Unpack parameter vector theta\n",
    "\tmu_prior = theta[0]\n",
    "\tsigma_prior = theta[1]\n",
    "\tsigma = theta[2]\n",
    "\tsigma_motor = theta[3]\n",
    "\t# Compute mean and std of the response\n",
    "\tw = sigma_prior**2/(sigma_prior**2 + sigma**2)    \n",
    "\tmu_resp = w*s + (1-w)*mu_prior\n",
    "\tsigma_resp = np.sqrt(w**2*sigma**2 + sigma_motor**2)\n",
    "\treturn mu_resp, sigma_resp\n",
    "\n",
    "def posterior_mean(x, sigma, mu_s, sigma_s1, sigma_s2, w_s):\n",
    "\tL1 = w_s * sps.norm.pdf(x, mu_s, np.sqrt( sigma**2 + sigma_s1**2 ))\n",
    "\tL2 = ( 1 - w_s ) * sps.norm.pdf(x, mu_s, np.sqrt( sigma**2 + sigma_s2**2 ))\n",
    "\n",
    "\tmu_post_1, _ = gaussian_response(x, (mu_s, sigma_s1, sigma, 0))\n",
    "\tmu_post_2, _ = gaussian_response(x, (mu_s, sigma_s2, sigma, 0))\n",
    "\n",
    "\treturn (L1 / (L1 + L2)) * mu_post_1 + (L2 / (L1 + L2)) * mu_post_2\n",
    "\n",
    "def log_likelihood(theta, data):\n",
    "\ts = data[:, 0]\n",
    "\tr = data[:, 1]\n",
    "\tsigma, lapse, w_s, mu_s, sigma_s1, sigma_s2 = theta\n",
    "\tNx = 2 ** 10 + 1\n",
    "\tlower_bound = s.min() - 5 * sigma\n",
    "\tupper_bound = s.max() + 5 * sigma\n",
    "\tx_grid = np.linspace(lower_bound, upper_bound, Nx)\n",
    "\tdx = x_grid[1].flatten() - x_grid[0].flatten()\n",
    "\t\n",
    "\tintegral = sp.integrate.romb(\n",
    "\t\tsps.norm.pdf(\n",
    "\t\t\t\tx_grid\n",
    "\t\t\t\t,s.reshape(-1, 1)\n",
    "\t\t\t\t,sigma\n",
    "\t\t\t) * sps.norm.pdf(\n",
    "\t\t\t\tr.reshape(-1, 1)\n",
    "\t\t\t\t,posterior_mean(x_grid, sigma, mu_s, sigma_s1, sigma_s2, w_s)\n",
    "\t\t\t\t,sigma_motor\n",
    "\t\t), dx=dx)\n",
    "\t\n",
    "\tlikelihoods = (1 - lapse) * integral + lapse * (1 / 1500)\n",
    "\treturn np.sum(np.log(likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part a)\n",
      "sanity check subject 5 log likelihood: -5971.377804064764\n"
     ]
    }
   ],
   "source": [
    "subject = 5\n",
    "s = np.array(df['Stimulus (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])\n",
    "r = np.array(df['Response (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])\n",
    "\n",
    "print(\"part a)\")\n",
    "result = log_likelihood((100, 0.01, 0.5, 787, 100, 120), np.column_stack((s, r)))\n",
    "print(\"sanity check subject 5 log likelihood:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    from pybads.bads import BADS\n",
    "    method = 'BADS'\n",
    "except:\n",
    "    method = 'L-BFGS-B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic_list = list()\n",
    "bic_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part b)\n",
      "Run 0: log-likelihood -11519.76822570033\n",
      "Run 1: log-likelihood -11517.806991192938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4013008/1309567271.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(likelihoods))\n",
      "/home/percy/.local/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2: log-likelihood -11949.408593987384\n",
      "The maximum-likelihood solution for subject 1  is theta_ML = [ 26.42351466   0.           0.99999945 784.49091794  30.14514513\n",
      " 141.51852176] with log-likelihood: -11517.806991192938\n",
      "Run 0: log-likelihood -5569.101435136236\n",
      "Run 1: log-likelihood -5674.2149195975635\n",
      "Run 2: log-likelihood -5545.126653382152\n",
      "The maximum-likelihood solution for subject 2  is theta_ML = [ 19.04207428   0.           1.         747.5572154   32.71277122\n",
      " 124.75943311] with log-likelihood: -5545.126653382152\n",
      "Run 0: log-likelihood -6131.2615537862985\n",
      "Run 1: log-likelihood -6121.791119026813\n",
      "Run 2: log-likelihood -6119.781988684902\n",
      "The maximum-likelihood solution for subject 3  is theta_ML = [103.72088193   0.00609206   0.51482556 744.05058406 203.54206234\n",
      "  48.29926865] with log-likelihood: -6119.781988684902\n",
      "Run 0: log-likelihood -6003.726797615023\n",
      "Run 1: log-likelihood -5990.765087062951\n",
      "Run 2: log-likelihood -5990.804842090428\n",
      "The maximum-likelihood solution for subject 4  is theta_ML = [144.26676151   0.           0.90901974 715.21454834 104.00850329\n",
      " 220.05293045] with log-likelihood: -5990.765087062951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4013008/1309567271.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  return (L1 / (L1 + L2)) * mu_post_1 + (L2 / (L1 + L2)) * mu_post_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0: log-likelihood -5913.50043627637\n",
      "Run 1: log-likelihood -5906.645454104711\n",
      "Run 2: log-likelihood -5907.23392671116\n",
      "The maximum-likelihood solution for subject 5  is theta_ML = [ 51.97089424   0.00189866   0.60609708 813.29662502  59.77803584\n",
      " 133.88605985] with log-likelihood: -5906.645454104711\n",
      "Run 0: log-likelihood -6002.884049650458\n",
      "Run 1: log-likelihood -6023.2035118070235\n",
      "Run 2: log-likelihood -5932.15674803648\n",
      "The maximum-likelihood solution for subject 6  is theta_ML = [ 67.60804464   0.00250553   0.07000744 774.96807981 344.25367417\n",
      "  82.68171786] with log-likelihood: -5932.15674803648\n"
     ]
    }
   ],
   "source": [
    "print(\"part b)\")\n",
    "lower_bounds = np.array([0.001, 0, 0., 650, 0.001, 0.001])\n",
    "upper_bounds = np.array([400, 1, 1, 900, 400, 400])\n",
    "\n",
    "num_runs = 3\n",
    "\n",
    "def multioptimize(target_fun,lower_bounds,upper_bounds,plausible_lower_bounds,plausible_upper_bounds,num_runs=3,method='L-BFGS-B'):\n",
    "\t\"\"\"Simple function for multi-start optimization.\"\"\"\n",
    "\t# Run num_runs optimization runs from different starting points    \n",
    "\tnum_params = lower_bounds.shape[0]\n",
    "\ttheta_res = np.zeros((num_runs,num_params))\n",
    "\tnll_res = np.zeros(num_runs)    \n",
    "\t\n",
    "\tfor index in range(num_runs):\n",
    "\t\tif index == 0:\n",
    "\t\t\ttheta0 = 0.5*(plausible_lower_bounds + plausible_upper_bounds)\n",
    "\t\telse:\n",
    "\t\t\ttheta0 = np.random.uniform(low=plausible_lower_bounds,high=plausible_upper_bounds)\n",
    "\t\t\n",
    "\t\tif method == 'L-BFGS-B':\n",
    "\t\t\tbounds = sp.optimize.Bounds(lower_bounds,upper_bounds,True) # Set hard bounds\n",
    "\t\t\tres = sp.optimize.minimize(target_fun, theta0, method='L-BFGS-B', bounds=bounds)\n",
    "\t\t\tnll_res[index] = res.fun\n",
    "\t\t\ttheta_res[index] = res.x\n",
    "\t\telif method == 'BADS':\n",
    "\t\t\tbads = BADS(target_fun, theta0, lower_bounds, upper_bounds, plausible_lower_bounds, plausible_upper_bounds)\n",
    "\t\t\tres = bads.optimize()\n",
    "\t\t\tnll_res[index] = res.fval\n",
    "\t\t\ttheta_res[index] = res.x\n",
    "\t\telse:\n",
    "\t\t\terror('Unknown optimization method.')\n",
    "\t\tprint('Run {}: log-likelihood {}'.format(index, -nll_res[index]))\n",
    "\t\t\n",
    "\t# Pick the best solution\n",
    "\tidx_best = np.argmin(nll_res)\n",
    "\tnll_best = nll_res[idx_best]\n",
    "\ttheta_best = theta_res[idx_best]        \n",
    "\treturn nll_best,theta_best\n",
    "aic_list = list()\n",
    "for subj in np.unique(df['Subject id']):\n",
    "\ts = np.array(df['Stimulus (ms)'][(df['Subject id'] == subj) & (df['Session id'] > 1)])\n",
    "\tr = np.array(df['Response (ms)'][(df['Subject id'] == subj) & (df['Session id'] > 1)])\n",
    "\n",
    "\ttarget_fun = lambda theta_: -log_likelihood(theta_, np.column_stack((s, r)))\n",
    "\n",
    "\tnll_best,theta_best = multioptimize(\n",
    "\t\ttarget_fun\n",
    "\t\t,lower_bounds\n",
    "\t\t,upper_bounds\n",
    "\t\t,lower_bounds\n",
    "\t\t,upper_bounds\n",
    "\t\t,num_runs\n",
    "\t\t,method=method\n",
    "\t)\n",
    "\n",
    "\tprint(f\"The maximum-likelihood solution for subject {subj}  is theta_ML = {theta_best} with log-likelihood: {-nll_best}\")\n",
    "\taic_list.append(2 * 6 - 2 * (-nll_best))\n",
    "\tbic_list.append(6 * np.log(len(s)) - 2 * (-nll_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part d)\n",
      "summed aic for mismatched prior model: 82096.56584492828\n",
      "summed bic for mismatched prior model: 82277.7739113762\n"
     ]
    }
   ],
   "source": [
    "print(\"part d)\")\n",
    "print(f\"summed aic for mismatched prior model: {np.sum(aic_list)}\")\n",
    "print(f\"summed bic for mismatched prior model: {np.sum(bic_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, data):\n",
    "\ts = data[:, 0]\n",
    "\tr = data[:, 1]\n",
    "\tsigma, lapse, mu_s, sigma_s = theta\n",
    "\tNx = 2 ** 10 + 1\n",
    "\tlower_bound = s.min() - 5 * sigma\n",
    "\tupper_bound = s.max() + 5 * sigma\n",
    "\tx_grid = np.linspace(lower_bound, upper_bound, Nx)\n",
    "\tdx = x_grid[1].flatten() - x_grid[0].flatten()\n",
    "\t\n",
    "\n",
    "\tposterior_mean = (sigma_s**2 / (sigma**2 + sigma_s**2)) * x_grid + (sigma**2 / (sigma**2 + sigma_s**2)) * mu_s\n",
    "\tintegral = sp.integrate.romb(\n",
    "\t\tsps.norm.pdf(\n",
    "\t\t\t\tx_grid\n",
    "\t\t\t\t,s.reshape(-1, 1)\n",
    "\t\t\t\t,sigma\n",
    "\t\t\t) * sps.norm.pdf(\n",
    "\t\t\t\tr.reshape(-1, 1)\n",
    "\t\t\t\t,posterior_mean\n",
    "\t\t\t\t,sigma_motor\n",
    "\t\t), dx=dx)\n",
    "\t\n",
    "\tlikelihoods = (1 - lapse) * integral + lapse * (1 / 1500)\n",
    "\treturn np.sum(np.log(likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part c)\n",
      "sanity check subject 5 log likelihood: -5950.256454262555\n"
     ]
    }
   ],
   "source": [
    "subject = 5\n",
    "s = np.array(df['Stimulus (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])\n",
    "r = np.array(df['Response (ms)'][(df['Subject id'] == subject) & (df['Session id'] > 1)])\n",
    "\n",
    "print(\"part c)\")\n",
    "result = log_likelihood((100, 0.01, 787.5, 128.1), np.column_stack((s, r)))\n",
    "print(\"sanity check subject 5 log likelihood:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4013008/3609839492.py:25: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(likelihoods))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0: log-likelihood -11716.016367838754\n",
      "Run 1: log-likelihood -11669.141421238648\n",
      "Run 2: log-likelihood -11624.338687099042\n",
      "The maximum-likelihood solution for subject 1  is theta_ML = [ 95.81838997   0.         787.5        128.1       ] with log-likelihood: -11624.338687099042\n",
      "Run 0: log-likelihood -5702.843759831729\n",
      "Run 1: log-likelihood -5646.249187880065\n",
      "Run 2: log-likelihood -5666.448316680093\n",
      "The maximum-likelihood solution for subject 2  is theta_ML = [ 57.45051873   0.         787.5        128.1       ] with log-likelihood: -5646.249187880065\n",
      "Run 0: log-likelihood -6199.7233595703065\n",
      "Run 1: log-likelihood -6137.264070945046\n",
      "Run 2: log-likelihood -6309.195390066335\n",
      "The maximum-likelihood solution for subject 3  is theta_ML = [107.48641423   0.00982269 787.5        128.1       ] with log-likelihood: -6137.264070945046\n",
      "Run 0: log-likelihood -6120.970936280577\n",
      "Run 1: log-likelihood -6103.817940474304\n",
      "Run 2: log-likelihood -6103.817940492742\n",
      "The maximum-likelihood solution for subject 4  is theta_ML = [152.87176673   0.00157207 787.5        128.1       ] with log-likelihood: -6103.817940474304\n",
      "Run 0: log-likelihood -5913.269617863316\n",
      "Run 1: log-likelihood -5913.269617840949\n",
      "Run 2: log-likelihood -5913.269628495707\n",
      "The maximum-likelihood solution for subject 5  is theta_ML = [ 63.91674282   0.00162411 787.5        128.1       ] with log-likelihood: -5913.269617840949\n",
      "Run 0: log-likelihood -5941.674099005908\n",
      "Run 1: log-likelihood -5941.674099030898\n",
      "Run 2: log-likelihood -5941.674099104811\n",
      "The maximum-likelihood solution for subject 6  is theta_ML = [ 88.56303148   0.00175278 787.5        128.1       ] with log-likelihood: -5941.674099005908\n"
     ]
    }
   ],
   "source": [
    "sigma_motor = 70\n",
    "\n",
    "lower_bounds = np.array([0.001, 0,  787.5, 128.1])\n",
    "upper_bounds = np.array([400, 1, 787.5, 128.1])\n",
    "\n",
    "num_runs = 3\n",
    "aic_list_ideal = list()\n",
    "bic_list_ideal = list()\n",
    "for subj in np.unique(df['Subject id']):\n",
    "\ts = np.array(df['Stimulus (ms)'][(df['Subject id'] == subj) & (df['Session id'] > 1)])\n",
    "\tr = np.array(df['Response (ms)'][(df['Subject id'] == subj) & (df['Session id'] > 1)])\n",
    "\n",
    "\ttarget_fun = lambda theta_: -log_likelihood(theta_, np.column_stack((s, r)))\n",
    "\n",
    "\tnll_best,theta_best = multioptimize(\n",
    "\t\ttarget_fun\n",
    "\t\t,lower_bounds\n",
    "\t\t,upper_bounds\n",
    "\t\t,lower_bounds\n",
    "\t\t,upper_bounds\n",
    "\t\t,num_runs\n",
    "\t\t,method=method\n",
    "\t)\n",
    "\taic_list_ideal.append(2 * 2 - 2 * (-nll_best))\n",
    "\tbic_list_ideal.append(2 * np.log(len(s)) - 2 * (-nll_best))\n",
    "\tprint(f\"The maximum-likelihood solution for subject {subj}  is theta_ML = {theta_best} with log-likelihood: {-nll_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part d)\n",
      "summed aic for ideal gaussian model: 82757.22720649061\n",
      "summed bic for ideal gaussian model: 82817.62989530661\n"
     ]
    }
   ],
   "source": [
    "print(\"part d)\")\n",
    "print(f\"summed aic for ideal gaussian model: {np.sum(aic_list_ideal)}\")\n",
    "print(f\"summed bic for ideal gaussian model: {np.sum(bic_list_ideal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
