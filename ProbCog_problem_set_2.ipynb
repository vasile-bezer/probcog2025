{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Data Science  \n",
    "DATA20047 Probabilistic Cognitive Modelling - Spring 2025  \n",
    "Luigi Acerbi  \n",
    "\n",
    "# Problem Set 2: Response distribution and model fitting\n",
    "\n",
    "- This homework problem set focuses on **Week 3 and 4** of the course.\n",
    "- This problem set is worth **25 points** in total (out of 100 for the full course).\n",
    "- Check the submission deadline on Moodle!\n",
    "\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "Submission must be perfomed entirely on Moodle (**not** by email).\n",
    "1. When you have completed the exercises, save the notebook.\n",
    "2. Report your solutions and answers on Moodle (\"*Problem set 2 answer return*\").\n",
    "3. Submit two files on Moodle (\"*Problem set 2 notebook return*\"): \n",
    "  - The notebook as `.ipynb`.\n",
    "  - The same notebook downloaded as `.pdf`.\n",
    "\n",
    "#### How to save the notebook as PDF\n",
    "\n",
    "There are various ways to save the Jupyter notebook as PDF, depending on the version of Jupyter notebook you have.\n",
    "\n",
    "- In older versions, you should be able to select \"File\" > \"Print Preview\" and then print the page to PDF using your browser (remember to enter the Print Preview first).\n",
    "- In more recent versions, you can select \"File\" > \"Save and Export Notebook As\" > \"PDF\".\n",
    "  * For this to work, you may need to install [Pandoc](https://pandoc.org/installing.html) first.\n",
    "  * Compiling to PDF might take a while.\n",
    "\n",
    "## IMPORTANT\n",
    "\n",
    "1. Do not share your code and answers with others. Contrary to the class exercises, which you can do with others, these problems are *not* group work and must be done individually.\n",
    "2. It is allowed to use snippets of code from the lecture exercises and model solutions.\n",
    "3. It is your responsibility to ensure that the notebook has fully finished running all the cells, all the plots view properly etc. before submitting it. However, the notebook should be runnable from scratch if needed (\"Kernel > Restart & Run All\").\n",
    "4. Submit your work by the deadline.\n",
    "5. Unless stated otherwise, please report your numerical answers in Moodle with full numerical precision (~14-15 digits), unless the answer is an integer.\n",
    "6. If you are confused, think there is a mistake or find things too difficult, please ask on Moodle.\n",
    "\n",
    "## References\n",
    "\n",
    "- \\[**MKG23**\\] Ma WJ, KÃ¶rding K, and Goldreich D. \"Bayesian Models of Perception and Action: An Introduction\". MIT Press, 2023.\n",
    "- \\[**AWV12**\\] Acerbi L, Wolpert DM, Vijayakumar S. \"Internal Representations of Temporal Statistics and Feedback Calibrate Motor-Sensory Interval Timing\". *PLoS Computational Biology*, 2012. [Link](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.1 (7 pts)\n",
    "\n",
    "#### Bayesian observer performance with different priors\n",
    "\n",
    "> This question explores how a Bayesian observer's performance depends on their prior beliefs about the stimulus distribution. We'll compare the Root Mean Squared Error (RMSE) for observers with different priors, demonstrating a key principle in Bayesian observer modelling: performance is optimal (lowest RMSE) when the observer's prior matches the true stimulus distribution. This problem draws on concepts from Week 3, including Bayesian estimation and RMSE calculations. See Chapter 4.5 of \\[**MKG23**\\] and the lecture notes for Week 3.\n",
    "\n",
    "Consider a Bayesian observer estimating a stimulus with true distribution $p(s) = \\text{Uniform}(s; -5, 5)$. The measurement process is noisy, described by a Gaussian distribution (and likelihood) $p(x|s) = \\mathcal{N}\\left(x; s, \\sigma^2 \\right)$ with $\\sigma = 2$.\n",
    "\n",
    "The observer:\n",
    "- Uses the posterior mean estimator $\\hat{s}_{PM}$.\n",
    "- Has no response noise.\n",
    "- May use a prior $q(s)$ that differs from the true stimulus distribution $p(s)$, i.e., a *mismatched* prior.\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "Calculate the total RMSE for three different cases:\n",
    "\n",
    "- a) The observer uses the correct prior: $q(s) = p(s) = \\text{Uniform}(s; -5, 5)$.\n",
    "- b) The observer uses a Gaussian approximation of the true distribution: $q(s) = \\mathcal{N}\\left(s; \\mu_s, \\sigma_s^2 \\right)$, where $\\mu_s$ and $\\sigma_s^2$ match the mean and variance of $p(s)$.\n",
    "   - *Note*: For a continuous uniform distribution on the $[a,b]$ interval, the variance is $(b-a)^2/12$.\n",
    "- c) The observer uses a wider uniform prior: $q(s) = \\text{Uniform}\\left(s; -8, 8 \\right)$.\n",
    "\n",
    "Report your results in Moodle. The accepted tolerance is $\\pm 0.001$ from the true value.\n",
    "\n",
    "#### Key equations\n",
    "\n",
    "Recall that the (total) RMSE of an estimator $\\hat{s}$ is defined as\n",
    "$$\n",
    "\\text{RMSE}[\\hat{s}] = \\sqrt{\\int \\text{MSE}\\left[\\hat{s}|s\\right] p(s) ds}\n",
    "$$\n",
    "where $p(s)$ is the true empirical distribution and $\\text{MSE}\\left[\\hat{s}|s\\right]$ is the mean squared error at each stimulus, defined as:\n",
    "$$\n",
    "\\text{MSE}\\left[\\hat{s}|s\\right] = \\mathbb{E}_{\\hat{s}|s}\\left[\\left(\\hat{s}-s\\right)^2|s \\right] = \\text{Bias}\\left[\\hat{s}|s\\right]^2 + \\text{Var}\\left[\\hat{s}|s\\right],\n",
    "$$\n",
    "where the definitions for bias and variance can be found in the textbook or lecture notes.\n",
    "\n",
    "\n",
    "#### Hints\n",
    "- You may be able to solve some of these problems analytically, but others will require numerical integration (e.g., `scipy.integrate.romb` or others).\n",
    "- Note that changing the prior $q(s)$ will change $\\hat{s}(x)$, but nothing else! So once you manage to compute (a), you should be able to compute (b) and (c) with a small change to the code, only where $\\hat{s}(x)$ is computed.\n",
    "- You may want to check out Exercise 3.3 of the lecture notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior_mean_1d(s_grid, prior_pdf, likelihood):\n",
    "    \"\"\"Compute s_hat_PM (posterior mean) for an arbitrary prior and likelihood in 1d.\"\"\"\n",
    "    ds = s_grid.flatten()[1] - s_grid.flatten()[0] # grid spacing\n",
    "    protoposterior = prior_pdf * likelihood    \n",
    "    normalization_constant = sp.integrate.romb(protoposterior, dx=ds, axis=0)\n",
    "    posterior_pdf = protoposterior / normalization_constant\n",
    "    posterior_mean = sp.integrate.romb(s_grid * posterior_pdf, dx=ds, axis=0)\n",
    "    return posterior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = -5., 5.\n",
    "sigma = 2.\n",
    "\n",
    "Nx = Ns = 2**11+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "total rmse: 1.5980857171741227\n"
     ]
    }
   ],
   "source": [
    "print('a)')\n",
    "\n",
    "upper_bound = b + sigma * 8\n",
    "lower_bound = a - sigma * 8\n",
    "x_row = np.linspace(lower_bound, upper_bound, Nx).reshape((1,Nx))\n",
    "s_col = np.linspace(lower_bound, upper_bound, Ns).reshape((Ns,1))\n",
    "dx = x_row.flatten()[1] - x_row.flatten()[0]\n",
    "ds = s_col.flatten()[1] - s_col.flatten()[0]\n",
    "\n",
    "likelihood_pdf = sps.norm.pdf(x_row, s_col, sigma)\n",
    "prior_pdf = sps.uniform.pdf(s_col, a, b - a)\n",
    "\n",
    "s_hat = compute_posterior_mean_1d(s_col, prior_pdf, likelihood_pdf)\n",
    "\n",
    "bias = sp.integrate.romb(s_hat * likelihood_pdf, dx=dx, axis=1) - s_col.flatten()\n",
    "var = sp.integrate.romb(s_hat**2 * likelihood_pdf, dx=dx, axis = 1) - sp.integrate.romb(s_hat*likelihood_pdf, dx=dx, axis=1)**2\n",
    "\n",
    "mse = (bias**2+var)\n",
    "\n",
    "print(f\"total rmse: {np.sqrt(sp.integrate.romb(mse*prior_pdf.flatten(), dx = ds, axis = 0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b)\n",
      "total rmse: 1.644190739550082\n"
     ]
    }
   ],
   "source": [
    "print('b)')\n",
    "\n",
    "mu_s = .5 * (a+b)\n",
    "sigma_s = np.sqrt(1/12 * (b-a)**2)\n",
    "\n",
    "lower_bound = mu_s - sigma * 8\n",
    "upper_bound = mu_s + sigma * 8\n",
    "\n",
    "x_row = np.linspace(lower_bound, upper_bound, Nx).reshape((1,Nx))\n",
    "s_col = np.linspace(lower_bound, upper_bound, Ns).reshape((Ns,1))\n",
    "dx = x_row.flatten()[1] - x_row.flatten()[0]\n",
    "ds = s_col.flatten()[1] - s_col.flatten()[0]\n",
    "\n",
    "prior_pdf = sps.norm.pdf(s_col, mu_s, sigma_s)\n",
    "likelihood_pdf = sps.norm.pdf(x_row, s_col, sigma)\n",
    "\n",
    "s_hat = compute_posterior_mean_1d(s_col, prior_pdf, likelihood_pdf)\n",
    "\n",
    "\n",
    "bias = sp.integrate.romb(s_hat * likelihood_pdf, dx=dx, axis=1) - s_col.flatten()\n",
    "var = sp.integrate.romb(s_hat**2 * likelihood_pdf, dx=dx, axis = 1) - sp.integrate.romb(s_hat*likelihood_pdf, dx=dx, axis=1)**2\n",
    "\n",
    "mse = (bias**2+var)\n",
    "\n",
    "print(f\"total rmse: {np.sqrt(sp.integrate.romb(mse*prior_pdf.flatten(), dx = ds, axis = 0))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c)\n",
      "total rmse: 1.9159070867805754\n"
     ]
    }
   ],
   "source": [
    "print('c)')\n",
    "\n",
    "true_a, true_b = -5., 5.\n",
    "a, b = -8., 8.  \n",
    "\n",
    "lower_bound = a - sigma * 8\n",
    "upper_bound = b + sigma * 8\n",
    "\n",
    "true_lower_bound = true_a - sigma * 8\n",
    "true_upper_bound = true_b + sigma * 8\n",
    "true_s_col = np.linspace(true_lower_bound, true_upper_bound, Ns).reshape((Ns,1))\n",
    "\n",
    "x_row = np.linspace(lower_bound, upper_bound, Nx).reshape((1,Nx))\n",
    "s_col = np.linspace(lower_bound, upper_bound, Ns).reshape((Ns,1))\n",
    "dx = x_row.flatten()[1] - x_row.flatten()[0]\n",
    "ds = s_col.flatten()[1] - s_col.flatten()[0]\n",
    "\n",
    "likelihood_pdf = sps.norm.pdf(x_row, s_col, sigma)\n",
    "mismatched_prior_pdf = sps.uniform.pdf(s_col, a, b - a)\n",
    "true_prior_pdf = sps.uniform.pdf(true_s_col, true_a, true_b - true_a)\n",
    "s_hat = compute_posterior_mean_1d(s_col, mismatched_prior_pdf, likelihood_pdf)\n",
    "\n",
    "bias = sp.integrate.romb(s_hat * likelihood_pdf, dx=dx, axis=1) - s_col.flatten()\n",
    "var = sp.integrate.romb(s_hat**2 * likelihood_pdf, dx=dx, axis=1) - sp.integrate.romb(s_hat * likelihood_pdf, dx=dx, axis=1)**2\n",
    "\n",
    "mse = (bias**2 + var)\n",
    "\n",
    "total_rmse = np.sqrt(sp.integrate.romb(mse * true_prior_pdf.flatten(), dx=ds, axis=0))\n",
    "\n",
    "print(f\"total rmse: {total_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.2 (6 pts)\n",
    "\n",
    "#### Response distributions in time perception\n",
    "\n",
    "> This question explores how different experimental conditions affect the distribution of responses in a time perception task. We'll analyze how an observer's responses vary when exposed to different ranges of time intervals, incorporating both perceptual and motor noise according to Weber's law. Our analysis follows \\[**JS10**\\] under different assumptions about the Bayesian observer. This problem builds on concepts from Week 3, including MAP estimation and response distributions.\n",
    "\n",
    "Consider the time perception experiment from \\[**JS10**\\] which we analyzed in Exercise 3.5.\n",
    "We recall the setup below. Note that there are differences from Exercise 3.5 (marked as **NEW**):\n",
    "- In this experiment, an observer is asked to judge the time interval $s$ between two flashes, measured in milliseconds (ms). In each trial, the duration is drawn from an interval distribution $p(s)$. \n",
    "- The experiment consist of three separate blocks of sessions run over multiple days. Each experimental block is identical except for the distribution of intervals $p(s)$. The distribution of time intervals in the three blocks are: \n",
    "  - $p_\\text{short}(s) = \\text{Uniform}\\left(s; 494, 847\\right)$\n",
    "  - $p_\\text{medium}(s) = \\text{Uniform}\\left(s; 671, 1023\\right)$\n",
    "  - $p_\\text{long}(s) = \\text{Uniform}\\left(s; 847,1200\\right)$\n",
    "- The observer's measurement distribution follows *Weber's law* (known in time perception as the \"scalar property\" of temporal judgment). According to this empirical law, the measurement noise is roughly linearly proportional to the magnitude of the stimulus. In formulas, $$p(x|s) = \\mathcal{N}\\left(x|s,\\sigma^2(s)\\right) \\qquad \\text{with} \\quad \\sigma(s) = w_s \\cdot s$$\n",
    "  where $w_s$ is known as *Weber's fraction*. Typical values of $w_s$ in timing are around 0.05-0.2, here we assume $w_s = 0.1$.\n",
    "- It is assumed that, after some practice, the observer develops a prior $p(s)$ which matches the stimulus distribution used in that block of sessions (and that the likelihood also matches the measurement distribution).\n",
    "- **NEW**: The observer responds with a deterministic estimate $\\hat{s}_\\text{MAP}$ which we assume is the mode of the posterior (also known as *maximum-a-posteriori* or MAP estimate). \n",
    "- **NEW**: The response is corrupted by motor noise which is proportional to the estimate:\n",
    "$$p(r|\\hat{s}) = \\mathcal{N}\\left(r; \\hat{s}, \\sigma_\\text{m}^2(\\hat{s})\\right) \\qquad \\text{with} \\quad \\sigma_\\text{m}(\\hat{s}) = w_\\text{m} \\cdot \\hat{s}$$ \n",
    "  where $w_\\text{m}$ represents the Weber's fraction for the motor noise. Here we assume $w_\\text{m} = 0.05$.\n",
    "  \n",
    "#### Tasks\n",
    "\n",
    "In this exercise, we look at the *distribution of responses* $p(r|s)$ that the experimenter would observe for a given stimulus in the three different experimental blocks (short, medium, or long). We consider the stimulus $s^\\star = 847$ ms which appears in all three experimental blocks.\n",
    "\n",
    "- a) Compute $p(r|s = s^\\star)$ for the \"short\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "- b) Compute $p(r|s = s^\\star)$ for the \"medium\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "- c) Compute $p(r|s = s^\\star)$ for the \"long\" block. Compute the mean and standard deviation of $p(r|s = s^\\star)$ and report them on Moodle.\n",
    "\n",
    "The accepted tolerance for the solutions is $\\pm 0.2$ ms for (a) and (b), and $\\pm 0.5$ ms for (c).\n",
    "\n",
    "#### Key equations\n",
    "Recall that the response distribution is given by:\n",
    "$$\n",
    "p(r|s) = \\int p(r|\\hat{s}(x)) p(x|s) dx,\n",
    "$$\n",
    "which in the general case can be solved via numerical integration.\n",
    "\n",
    "#### Hints \n",
    "- Be careful that the likelihood, $p(x|s)$ as a function of $s$, is *not* Gaussian, because $\\sigma(s)$ is not constant in $s$. As a consequence, the posterior will *not* be Gaussian. This affects the MAP estimate, $\\hat{s}_\\text{MAP}$, which you will need to compute numerically. As an example of this phenomenon of stimulus-dependent variance yielding a non-Gaussian likelihood, see Demo 3.4 in the lecture notebooks.\n",
    "- It is recommended that you first compute $\\hat{s}_\\text{MAP}(x)$ for a grid of $x$, and then compute the response distribution numerically via the integral above.\n",
    "- The MAP estimate $\\hat{s}_\\text{MAP}$ is the value of $s$ that maximizes the posterior $p(s|x)$. Note that this value does not depend on the normalization constant, so you can compute $p(s|x) \\propto p(s) p(x|s)$ for a (fine) grid of values `s_grid` and take the argument $s$ that maximizes this quantity.\n",
    "- Common mistake: $s^\\star = 847$ ms is the true stimulus chosen by the experimenter, the observer only receives noisy measurements $x$, not $s^\\star$!\n",
    "- Suggested pipeline: First compute $\\hat{s}_\\text{MAP}(x)$ for each value in a grid (`x_grid`); then compute the response distribution via numerical integration over that grid; finally compute summary statistics via numerical integration.\n",
    "\n",
    "#### Sanity checks\n",
    "- As an intermediate sanity check that you are computing the posterior and the estimate correctly, you can check that $\\hat{s}_\\text{MAP}(x = 759) \\approx 751.50$ for case (a), i.e. the \"short\" prior block.\n",
    "- Throughout your pipeline, double-check the sizes of the arrays you are using.\n",
    "- At the end, check that $\\int p(r|s) dr = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short block: mu = 809.00991118739, sigma = 65.63311779369755\n",
      "medium block: mu = 838.996632384212, sigma = 91.3745203363932\n",
      "long block: mu = 876.6418316088121, sigma = 63.579335559718054\n"
     ]
    }
   ],
   "source": [
    "a_short, b_short = 494., 847.\n",
    "a_medium, b_medium = 671., 1023.\n",
    "a_long, b_long = 847., 1200.\n",
    "\n",
    "s_star = 847\n",
    "w_s = 0.1\n",
    "w_m = 0.05\n",
    "\n",
    "lower_bound = 400 \n",
    "upper_bound = 1300\n",
    "\n",
    "Nx = Ns = 2**10+1\n",
    "\n",
    "s_grid = np.linspace(lower_bound, upper_bound, Ns)\n",
    "x_grid = np.linspace(lower_bound, upper_bound, Nx)\n",
    "ds = s_grid.flatten()[1] - s_grid.flatten()[0]\n",
    "dx = x_grid.flatten()[1] - x_grid.flatten()[0]\n",
    "\n",
    "priors = {\n",
    "    \"short\": sps.uniform.pdf(s_grid, a_short, b_short - a_short)\n",
    "    ,\"medium\": sps.uniform.pdf(s_grid, a_medium, b_medium - a_medium)\n",
    "    ,\"long\": sps.uniform.pdf(s_grid, a_long, b_long - a_long)\n",
    "}\n",
    "\n",
    "for block, prior_s in priors.items():\n",
    "    likelihood_pdf = sps.norm.pdf(x_grid, s_grid.reshape(-1, 1), w_s * s_grid.reshape(-1, 1))\n",
    "    posterior_pdf = prior_s.reshape(-1, 1) * likelihood_pdf\n",
    "    s_hat = s_grid[np.argmax(posterior_pdf, axis=0)]\n",
    "    \n",
    "    response_pdf = np.sum(\n",
    "        sps.norm.pdf(x_grid.reshape(1, -1), s_star, w_s * s_star) * sps.norm.pdf(x_grid.reshape(-1, 1), s_hat, w_m * s_hat)\n",
    "        ,axis = 1\n",
    "    )\n",
    "    response_pdf /= sp.integrate.romb(response_pdf, dx = dx)\n",
    "    mu_resp = sp.integrate.romb(x_grid * response_pdf, dx = dx)\n",
    "    sigma_resp = np.sqrt( sp.integrate.romb((x_grid - mu_resp)**2 * response_pdf, dx = dx) )\n",
    "    print(f\"{block} block: mu = {mu_resp}, sigma = {sigma_resp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.3 (6 pts)\n",
    "\n",
    "#### Model Fitting with Lapses in Time Perception\n",
    "\n",
    "> The key quantity for model fitting is the log-likelihood for a dataset and some model parameters. In this exercise, we compute the log-likelihood for a Bayesian observer model which also includes the possibility of *lapses*, a common mechanism used in cognitive science to explain away \"random\" responses and subjects' mistakes. This problem builds on concepts from Week 4, particularly model fitting and likelihood computation.\n",
    "\n",
    "In this question, we consider the datasets from Experiment 3 of \\[**AWV12**\\], as seen in Week 4. The experimental setup which involves time perception and interval reproduction is very similar to \\[**JS10**\\], so we can consider the same type of models.\n",
    "\n",
    "We analyze the data with the `gaussianobserverwithlapse` model, defined as follows:\n",
    "- We assume the observer builds a (mismatched) Gaussian prior $p(s) = \\mathcal{N}\\left(s| \\mu_\\text{prior}, \\sigma_\\text{prior}^2 \\right)$ over the stimuli (time intervals). \n",
    "- We assume that the measurement distribution and likelihood are also Gaussian, $p(x|s) = \\mathcal{N}\\left(x| s, \\sigma^2 \\right)$.\n",
    "- The observer uses the *posterior mean* estimator for the value of the stimulus, $\\hat{s}_\\text{PM}$.\n",
    "- Gaussian motor response noise is added to the estimate, $p(r|\\hat{s}) = \\mathcal{N}\\left(r| \\hat{s}, \\sigma_\\text{motor}^2 \\right)$.\n",
    "- In each trial, the observer lapses with probability $\\lambda$ (the *lapse rate*), in which case the response is drawn from $p_\\text{lapse}(r) = \\text{Uniform}\\left(r; 0, 1500 \\right)$ ms. Otherwise, the observer responds normally (according to $p(r|\\hat{s})$ described above) with probability $1 - \\lambda$. \n",
    "- The parameters of this model are $\\mathbf{\\theta} = \\left(\\mu_\\text{prior}, \\sigma_\\text{prior}, \\sigma, \\sigma_\\text{motor}, \\lambda \\right)$.\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "For parameter values $\\mathbf{\\theta}_\\star = \\left(\\mu_\\text{prior} = 780, \\sigma_\\text{prior} = 140, \\sigma = 90, \\sigma_\\text{motor} = 60, \\lambda = 0.02 \\right)$:\n",
    "\n",
    "- a) Compute the log-likelihood of model parameter $\\theta_\\star$ for the dataset of subject 2\n",
    "- b) Compute the log-likelihood of model parameter $\\theta_\\star$ for the dataset of subject 5\n",
    "\n",
    "Report your results on Moodle with high precision.\n",
    "\n",
    "#### Key equations\n",
    "Recall that for each trial $i$, the probability of observing response $r_i$ given stimulus $s_i$ is:\n",
    "$$p(r_i|s_i, \\theta) = (1-\\lambda) \\cdot p_\\text{normal}(r_i|s_i) + \\lambda \\cdot p_\\text{lapse}(r_i).$$\n",
    "\n",
    "The log-likelihood is the sum of log probabilities across all trials:\n",
    "$$\\log \\mathcal{L}(\\theta) = \\sum_{i=1}^N \\log p(r_i|s_i, \\theta).$$\n",
    "\n",
    "#### Hints\n",
    "- If you use code from the lectures, be careful about the model definition, as there may be subtle differences.\n",
    "- Remember to properly handle the response distribution with lapses (normal responses + lapses).\n",
    "- The response noise distribution $p(r|s_i)$ for normal (non-lapse) responses is obtained by marginalizing over the measurement $x$, as we saw earlier:\n",
    "  $p_\\text{normal}(r|s_i) = \\int p(r|\\hat{s}(x)) p(x|s_i) dx$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject id</th>\n",
       "      <th>Session id</th>\n",
       "      <th>Run id</th>\n",
       "      <th>Stimulus (ms)</th>\n",
       "      <th>Response (ms)</th>\n",
       "      <th>Stimulus id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>973.327049</td>\n",
       "      <td>862.947945</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>677.519900</td>\n",
       "      <td>574.920276</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>826.253049</td>\n",
       "      <td>870.995615</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>677.854859</td>\n",
       "      <td>695.055098</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>598.501198</td>\n",
       "      <td>632.981845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject id  Session id  Run id  Stimulus (ms)  Response (ms)  Stimulus id\n",
       "0           1           1       1     973.327049     862.947945          6.0\n",
       "1           1           1       1     677.519900     574.920276          2.0\n",
       "2           1           1       1     826.253049     870.995615          4.0\n",
       "3           1           1       1     677.854859     695.055098          2.0\n",
       "4           1           1       1     598.501198     632.981845          1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data of Experiment 3 of [AWV12] from .csv file to a Pandas dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lacerbi/prob-cog-mod-files/main/data/awv12_exp3.csv')\n",
    "\n",
    "# Remove unused columns (they deal with performance feedback, which we ignore in this lecture)\n",
    "df.drop(df.columns[[6, 7, 8]], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows with NaNs\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.shape: (2520,)\n",
      "r.shape: (2520,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example code to extract stimuli and responses for a single subject (here S1)\n",
    "subject = 1\n",
    "s = np.array(df['Stimulus (ms)'][df['Subject id'] == subject])\n",
    "r = np.array(df['Response (ms)'][df['Subject id'] == subject])\n",
    "print('s.shape:', s.shape)\n",
    "print('r.shape:', r.shape)\n",
    "\n",
    "plt.scatter(s, r)\n",
    "plt.xlabel('Stimulus $s$ (ms)')\n",
    "plt.ylabel('Response $r$ (ms)')\n",
    "plt.title('S' + str(subject))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_response(s,theta):\n",
    "    \"\"\"Compute mean and standard deviation of p(r|s; theta).\"\"\"\n",
    "    # Unpack parameter vector theta\n",
    "    mu_prior = theta[0]\n",
    "    sigma_prior = theta[1]\n",
    "    sigma = theta[2]\n",
    "    sigma_motor = theta[3]\n",
    "    # Compute mean and std of the response\n",
    "    w = sigma_prior**2/(sigma_prior**2 + sigma**2)    \n",
    "    mu_resp = w*s + (1-w)*mu_prior\n",
    "    sigma_resp = np.sqrt(w**2*sigma**2 + sigma_motor**2)\n",
    "    return mu_resp, sigma_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s.shape: (1512,)\n",
      "r.shape: (1512,)\n",
      "log likelihood for subject 2: -8577.318546123512\n",
      "s.shape: (1520,)\n",
      "r.shape: (1520,)\n",
      "log likelihood for subject 5: -9105.655523964238\n"
     ]
    }
   ],
   "source": [
    "def loglike(theta, stimuli, responses):\n",
    "    \n",
    "    mu_s, sigma_s, sigma, sigma_motor, lapse_rate = theta\n",
    "    mu_resp, sigma_resp = gaussian_response(stimuli, np.array( (mu_s, sigma_s, sigma, sigma_motor) ))\n",
    "    loglike_vec = sps.norm.logpdf(responses, mu_resp, sigma_resp)\n",
    "    \n",
    "    if lapse_rate > 0.:\n",
    "        likelihood_vec = np.exp(loglike_vec) # Exponentiate back to the likelihood\n",
    "        likelihood_with_lapse_vec = (1 - lapse_rate) * likelihood_vec + lapse_rate * sps.uniform.pdf(r, 0, 1500)\n",
    "        loglike_vec = np.log(likelihood_with_lapse_vec)\n",
    "    return np.sum(loglike_vec)\n",
    "\n",
    "\n",
    "theta_star = (780, 140, 90, 60, 0.02)\n",
    "subject_list = list( (2, 5) )\n",
    "\n",
    "for subj in subject_list:\n",
    "\ts = np.array(df[ 'Stimulus (ms)' ][df['Subject id'] == subj])\n",
    "\tr = np.array(df['Response (ms)'][df['Subject id'] == subj])\n",
    "\tprint('s.shape:', s.shape)\n",
    "\tprint('r.shape:', r.shape)\n",
    "\tprint(f\"log likelihood for subject {subj}: {loglike(theta_star, s, r)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2.4 (6 pts)\n",
    "\n",
    "#### Population-level Model Fitting Analysis\n",
    "\n",
    "> When fitting models to data, the experimenter may be interested in how model parameters are represented across the population (here represented by the group of subjects). A simple way to look at this is to examine the distribution of maximum-likelihood estimates for the parameters across subjects, in first instance by looking their mean and variability. This question builds on the model fitting concepts from Week 4, focusing on population-level analysis.\n",
    "\n",
    "We consider here the `idealgaussianobserverwithlapse` model. This model is the same as the `gaussianobserverwithlapse` of Question 2.3, but with fixed prior parameters:\n",
    "- Fixed prior mean: $\\mu_\\text{prior} = 787.5$ ms.\n",
    "- Fixed prior standard deviation: $\\sigma_\\text{prior} = 128.1$ ms.\n",
    "- Thus, the model has three free parameters: $\\theta = \\left(\\sigma, \\sigma_\\text{motor}, \\lambda \\right)$.\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "a) Perform individual subject fits:\n",
    "   - Fit the `idealgaussianobserverwithlapse` model separately to each of the six subjects' datasets using maximum-likelihood estimation.\n",
    "   - Compute the mean and standard deviation of each parameter ($\\sigma, \\sigma_\\text{motor}, \\lambda$) across subjects and report these in Moodle.\n",
    "   - Use the correction for degrees of freedom for standard deviation (`np.std(..., ddof=1)`).\n",
    "\n",
    "b) Perform pooled data analysis:\n",
    "   - Combine all subjects' data into a single dataset.\n",
    "   - Fit the model to this pooled dataset.\n",
    "   - Report the maximum-likelihood estimates for $\\sigma, \\sigma_\\text{motor}, \\lambda$ in Moodle.\n",
    "\n",
    "#### Key equations\n",
    "The log-likelihood for a dataset $\\mathcal{D}$ is:\n",
    "$$\\log \\mathcal{L}(\\theta; \\mathcal{D}) = \\sum_i \\log p(r_i|s_i, \\theta),$$\n",
    "where $p(r_i|s_i, \\theta)$ is defined as in Question 2.3.\n",
    "\n",
    "#### Hints\n",
    "- If you use code from the lectures for the `idealgaussianobserverwithlapse` model, be careful about the model definition.\n",
    "- Make sure your optimization routine finds the global maximum.\n",
    "- Watch for numerical stability issues in the optimization.\n",
    "- Remember that parameters have natural constraints ($\\sigma, \\sigma_\\text{motor} > 0$ and $0 \\leq \\lambda \\leq 1$).\n",
    "\n",
    "#### Sanity checks\n",
    "- Verify that the log-likelihood for subject 1 with $\\theta_\\star = \\left(\\sigma = 90, \\sigma_\\text{motor} = 80, \\lambda = 0.02\\right)$ is $\\log \\mathcal{L}(\\theta_\\star; \\mathcal{D}_1) \\approx -14709.795$.\n",
    "- All fitted parameters should be within reasonable ranges (e.g., $\\sigma, \\sigma_\\text{motor}$ should be positive but not huge).\n",
    "- The lapse rate $\\lambda$ should be small (typically < 0.1).\n",
    "\n",
    "#### Important note\n",
    "As we mentioned in class, fitting individual subjects' data is the best approach to describe individual behavior in cognitive science, but sometimes you will see studies only looking at pooled/group data. Be careful that pooling might hide what really happens, only giving a snapshot of the average behavior of the group, which might not correspond to what individuals do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    from pybads.bads import BADS\n",
    "    method = 'BADS'\n",
    "except:\n",
    "    method = 'L-BFGS-B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idealgaussianobserverwithlapse_loglike(theta,s_vec,r_vec):\n",
    "    \"\"\"Log-likelihood of ideal Gaussian observer with added lapse.\"\"\"\n",
    "    mu_prior = 787.5\n",
    "    sigma_prior = 128.1\n",
    "    sigma, sigma_motor, lapse_rate = theta\n",
    "    lapse_pdf = sps.uniform.pdf(r_vec, 0, 1500)\n",
    "    mu_resp, sigma_resp = gaussian_response(s_vec,np.array((mu_prior,sigma_prior,sigma,sigma_motor)))\n",
    "    # First, compute log-likelihood without probability of lapse\n",
    "    loglike_vec = sps.norm.logpdf(r_vec,mu_resp,sigma_resp) # Vector of log-likelihood per trials\n",
    "    # Now, add the probability of lapse\n",
    "    if lapse_rate > 0.:\n",
    "        likelihood_vec = np.exp(loglike_vec) # Exponentiate back to the likelihood\n",
    "        likelihood_with_lapse_vec = (1-lapse_rate)*likelihood_vec + lapse_rate*lapse_pdf\n",
    "        loglike_vec = np.log(likelihood_with_lapse_vec)\n",
    "        # This code snippet below uses the logsumexp trick, which is numerically more stable\n",
    "        # loglapse = np.log(lapse_rate*lapse_pdf)\n",
    "        # M = np.maximum(loglike, loglapse)\n",
    "        # loglike = np.log((1-lapse_rate)*np.exp(loglike-M) + np.exp(loglapse-M)) + M        \n",
    "    return np.sum(loglike_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a)\n",
      "Run 0: log-likelihood -14497.354655985197\n",
      "Run 1: log-likelihood -14497.354655713632\n",
      "Run 2: log-likelihood -14497.354655758234\n",
      "The maximum-likelihood solution (dataset S1) is theta_ML = [109.59652504  42.53783249   0.        ] with log-likelihood: -14497.354655713632\n",
      "Run 0: log-likelihood -8422.260464870466\n",
      "Run 1: log-likelihood -8422.26046486864\n",
      "Run 2: log-likelihood -8422.26046488416\n",
      "The maximum-likelihood solution (dataset S2) is theta_ML = [68.83577361 30.88192263  0.00504815] with log-likelihood: -8422.26046486864\n",
      "Run 0: log-likelihood -9190.376737245035\n",
      "Run 1: log-likelihood -9184.668323038133\n",
      "Run 2: log-likelihood -9184.726184815736\n",
      "The maximum-likelihood solution (dataset S3) is theta_ML = [115.92131353  71.98750422   0.01305079] with log-likelihood: -9184.668323038133\n",
      "Run 0: log-likelihood -9293.778660720549\n",
      "Run 1: log-likelihood -9293.778662167424\n",
      "Run 2: log-likelihood -9294.942955147957\n",
      "The maximum-likelihood solution (dataset S4) is theta_ML = [139.91187925  91.65221689   0.        ] with log-likelihood: -9293.778660720549\n",
      "Run 0: log-likelihood -9084.224657201035\n",
      "Run 1: log-likelihood -9084.224657098897\n",
      "Run 2: log-likelihood -9085.42199572434\n",
      "The maximum-likelihood solution (dataset S5) is theta_ML = [63.39585784 76.45988566  0.00830561] with log-likelihood: -9084.224657098897\n",
      "Run 0: log-likelihood -9107.775501344993\n",
      "Run 1: log-likelihood -9107.757200424494\n",
      "Run 2: log-likelihood -9107.757200427528\n",
      "The maximum-likelihood solution (dataset S6) is theta_ML = [93.89723238 73.25875665  0.00719761] with log-likelihood: -9107.757200424494\n",
      "optimal parameter list mean: [98.59309694 64.46301976  0.00560036]\n",
      "optimal parameter list sigma: [29.24031247 22.91533987  0.00506777]\n"
     ]
    }
   ],
   "source": [
    "print(\"a)\")\n",
    "lower_bounds = np.array([1.,1.,0.])\n",
    "upper_bounds = np.array([2000.,2000.,1.])\n",
    "\n",
    "num_runs = 3\n",
    "\n",
    "\n",
    "def multioptimize(target_fun,lower_bounds,upper_bounds,plausible_lower_bounds,plausible_upper_bounds,num_runs=3,method='L-BFGS-B'):\n",
    "    \"\"\"Simple function for multi-start optimization.\"\"\"\n",
    "    # Run num_runs optimization runs from different starting points    \n",
    "    num_params = lower_bounds.shape[0]\n",
    "    theta_res = np.zeros((num_runs,num_params))\n",
    "    nll_res = np.zeros(num_runs)    \n",
    "    \n",
    "    for index in range(num_runs):\n",
    "        if index == 0:\n",
    "            theta0 = 0.5*(plausible_lower_bounds + plausible_upper_bounds)\n",
    "        else:\n",
    "            theta0 = np.random.uniform(low=plausible_lower_bounds,high=plausible_upper_bounds)\n",
    "        \n",
    "        if method == 'L-BFGS-B':\n",
    "            bounds = sp.optimize.Bounds(lower_bounds,upper_bounds,True) # Set hard bounds\n",
    "            res = sp.optimize.minimize(target_fun, theta0, method='L-BFGS-B', bounds=bounds)\n",
    "            nll_res[index] = res.fun\n",
    "            theta_res[index] = res.x\n",
    "        elif method == 'BADS':\n",
    "            bads = BADS(target_fun, theta0, lower_bounds, upper_bounds, plausible_lower_bounds, plausible_upper_bounds)\n",
    "            res = bads.optimize()\n",
    "            nll_res[index] = res.fval\n",
    "            theta_res[index] = res.x\n",
    "        else:\n",
    "            error('Unknown optimization method.')\n",
    "        print('Run {}: log-likelihood {}'.format(index, -nll_res[index]))\n",
    "        \n",
    "    # Pick the best solution\n",
    "    idx_best = np.argmin(nll_res)\n",
    "    nll_best = nll_res[idx_best]\n",
    "    theta_best = theta_res[idx_best]        \n",
    "    return nll_best,theta_best\n",
    "\n",
    "subject_list = list( (1, 2, 3, 4, 5, 6) )\n",
    "optimal_params_list = list()\n",
    "for subj in subject_list:\n",
    "    s = np.array(df['Stimulus (ms)'][df['Subject id'] == subj])\n",
    "    r = np.array(df['Response (ms)'][df['Subject id'] == subj])\n",
    "    plausible_lower_bounds = np.array([np.mean(s)*0.05,np.mean(s)*0.05,0.01])\n",
    "    plausible_upper_bounds = np.array([np.mean(s)*0.20,np.mean(s)*0.20,0.05])\n",
    "\n",
    "    target_fun = lambda theta_: -idealgaussianobserverwithlapse_loglike(np.array(theta_), s, r)\n",
    "    nll_best,theta_best = multioptimize(\n",
    "        target_fun\n",
    "        ,lower_bounds\n",
    "        ,upper_bounds\n",
    "        ,plausible_lower_bounds\n",
    "        ,plausible_upper_bounds\n",
    "        ,num_runs\n",
    "        ,method=method\n",
    "    )\n",
    "    optimal_params_list.append(\n",
    "        np.array(theta_best)\n",
    "\t)\n",
    "    print(f\"The maximum-likelihood solution (dataset S{subj}) is theta_ML = {theta_best} with log-likelihood: {-nll_best}\")\n",
    "\n",
    "print(f\"optimal parameter list mean: {np.mean(optimal_params_list, axis=0)}\")\n",
    "print(f\"optimal parameter list sigma: {np.std(optimal_params_list, axis=0, ddof=1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b)\n",
      "Run 0: log-likelihood -60044.81166183457\n",
      "Run 1: log-likelihood -60044.8116614214\n",
      "Run 2: log-likelihood -60044.81166293305\n",
      "The maximum-likelihood solution (pooled dataset) is theta_ML = [98.09297545 64.11754746  0.00763866] with log-likelihood: -60044.8116614214\n"
     ]
    }
   ],
   "source": [
    "print(\"b)\")\n",
    "\n",
    "s_pooled = np.array(df['Stimulus (ms)'])\n",
    "r_pooled = np.array(df['Response (ms)'])\n",
    "target_fun_pooled = lambda theta_: -idealgaussianobserverwithlapse_loglike(np.array(theta_),s_pooled,r_pooled)\n",
    "\n",
    "\n",
    "nll_best,theta_best = multioptimize(target_fun_pooled,lower_bounds,upper_bounds,plausible_lower_bounds,plausible_upper_bounds,num_runs,method=method)\n",
    "print('The maximum-likelihood solution (pooled dataset) is theta_ML = {} with log-likelihood: {}'.format(\n",
    "    theta_best, -nll_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
