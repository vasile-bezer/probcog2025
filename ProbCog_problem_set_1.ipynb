{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Helsinki, Master's Programme in Data Science  \n",
    "DATA20047 Probabilistic Cognitive Modelling - Spring 2025  \n",
    "Luigi Acerbi  \n",
    "\n",
    "# Problem Set 1: Bayesian inference in perception\n",
    "\n",
    "- This homework problem set focuses on **Week 1 and 2** of the course.\n",
    "- This problem set is worth **20 points** in total (out of 100 for the full course).\n",
    "- Check the submission deadline on Moodle!\n",
    "\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "Submission must be perfomed entirely on Moodle (**not** by email).\n",
    "1. When you have completed the exercises, save the notebook.\n",
    "2. Report your solutions and answers on Moodle (\"*Problem set 1 answer return*\").\n",
    "3. Submit two files on Moodle (\"*Problem set 1 notebook return*\"): \n",
    "  - The notebook as `.ipynb`.\n",
    "  - The same notebook downloaded as `.pdf`\n",
    "\n",
    "#### How to save the notebook as PDF\n",
    "\n",
    "There are various ways to save the Jupyter notebook as PDF, depending on the version of Jupyter notebook you have.\n",
    "\n",
    "- In older versions, you should be able to select \"File\" > \"Print Preview\" and then print the page to PDF using your browser (remember to enter the Print Preview first).\n",
    "- In more recent versions, you can select \"File\" > \"Save and Export Notebook As\" > \"PDF\".\n",
    "  * For this to work, you may need to install [Pandoc](https://pandoc.org/installing.html) first.\n",
    "  * Compiling to PDF might take a while.\n",
    "\n",
    "## IMPORTANT\n",
    "\n",
    "1. Do not share your code and answers with others. Contrary to the class exercises, which you can do with others, these problems are *not* group work and must be done individually.\n",
    "2. It is allowed to use snippets of code from the lecture exercises and model solutions.\n",
    "3. It is your responsibility to ensure that the notebook has fully finished running all the cells, all the plots view properly etc. before submitting it. However, the notebook should be runnable from scratch if needed (\"Kernel > Restart & Run All\").\n",
    "4. Submit your work by the deadline.\n",
    "5. Unless stated otherwise, please report your numerical answers in Moodle with full numerical precision (~14-15 digits), unless the answer is an integer.\n",
    "6. If you are confused, think there is a mistake or find things too difficult, please ask on Moodle.\n",
    "\n",
    "## References\n",
    "\n",
    "- \\[**MKG23**\\] Ma WJ, Körding K, and Goldreich D. \"Bayesian Models of Perception and Action: An Introduction\". MIT Press, 2023.\n",
    "- *Acknowledgements*: Question 1.1 and 1.2 of this notebook are adapted from problems in \\[**MKG23**\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up -- do not change\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.1 (5 pts)\n",
    "\n",
    "> This question is about performing Bayesian inference in an \"everyday\" scenario, with some simplifying assumptions. Related material was covered in Week 1 of the course.\n",
    "\n",
    "\n",
    "You are one of 80 passengers waiting for your bag at an airport luggage carousel (see Section 2.5 of \\[**MKG23**\\]). We assume each passenger has one and only one bag. In general, your bag looks the same as 6% of all bags. In formulas:\n",
    "$$\n",
    "p(\\text{looks like your bag}|\\text{it is your bag}) = 1, \\qquad p(\\text{looks like your bag}|\\text{it is not your bag}) = 0.06.\n",
    "$$\n",
    "\n",
    "Derive a general expression for the probability that the bag you are viewing (which matches your bag visually) is your own, $$p(\\text{it is your bag} | \\text{looks like your bag}),$$ \n",
    "as a function of the number of bags $b$ you have viewed so far (before the current one). \n",
    "\n",
    "- a) What is $p(\\text{it is your bag} | \\text{looks like your bag})$ after 40 bags have gone by, none of which was yours (that is, $b = 40$)?\n",
    "- b) How many bags must you view (without finding your own) before the posterior probability $p(\\text{it is your bag}|\\text{looks like your bag})$ is equal or greater than 70%?\n",
    "\n",
    "Report your results in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[it is your bag | looks like your bag] after 0 bags have gone by: 0.17\n",
      "P[it is your bag | looks like your bag] after 1 bags have gone by: 0.18\n",
      "P[it is your bag | looks like your bag] after 40 bags have gone by: 0.30\n",
      "P[it is your bag | looks like your bag] after 78 bags have gone by: 0.94\n",
      "P[it is your bag | looks like your bag] after 79 bags have gone by: 1.00\n",
      "Bags to view \u001b[1mbefore\u001b[0m P[it is your bag | looks like your bag] is => 0.7: 72\n",
      "P[it is your bag | looks like your bag] at 72 iterations: 0.7042253521126761 \n"
     ]
    }
   ],
   "source": [
    "# code here...\n",
    "\n",
    "def p(b = 0):\n",
    "    return ( 1 / (80-b) ) / (1 / (80-b) + 6/100 * (80-1-b)/(80-b))\n",
    "\n",
    "print(f\"P[it is your bag | looks like your bag] after 0 bags have gone by: {p(b = 0):.2f}\")\n",
    "print(f\"P[it is your bag | looks like your bag] after 1 bags have gone by: {p(b = 1):.2f}\")\n",
    "print(f\"P[it is your bag | looks like your bag] after 40 bags have gone by: {p(b = 40):.2f}\")\n",
    "print(f\"P[it is your bag | looks like your bag] after 78 bags have gone by: {p(b = 78):.2f}\")\n",
    "print(f\"P[it is your bag | looks like your bag] after 79 bags have gone by: {p(b = 79):.2f}\")\n",
    "\n",
    "# sum = 0\n",
    "iterations = 0\n",
    "for i in range(0, 80):\n",
    "    # sum += p(b = i)\n",
    "    if p(b = i) >= 7/10: \n",
    "        iterations = i\n",
    "        break\n",
    "print(f\"Bags to view \\033[1mbefore\\033[0m P[it is your bag | looks like your bag] is => 0.7: {iterations}\")\n",
    "print(f\"P[it is your bag | looks like your bag] at {iterations} iterations: {p(b = iterations)} \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.2 (5 pts)\n",
    "\n",
    "> This question deals with how perception about the world is influenced by the statistics of the environment. See Chapter 2 and particularly Section 2.6 of \\[**MKG23**\\].\n",
    "\n",
    "\n",
    "Imagine you live in a very boring world consisting of a 2 x 10 grid of squares:\n",
    "\n",
    "```\n",
    "▢▢▢▢▢▢▢▢▢▢\n",
    "▢▢▢▢▢▢▢▢▢▢\n",
    "```\n",
    "Only two things ever happen in this world: \n",
    "- $H1$ (\"vertical bar\"): With a probability of 30%, a vertical bar will appear in this world, consisting of two black squares in a column, chosen so that each possible column is equally probable. \n",
    "- $H2$ (\"independent dots\"): With a probability of 70%, one black square will appear in a random position in the top row (uniformly chosen), and another black square will appear in a random position in the bottom row (uniformly chosen, independently from the first row). \n",
    "\n",
    "When doing inference, we will refer to these possibilities as Hypotheses 1 and 2 ($H1$ and $H2$), respectively.\n",
    "\n",
    "- a) Suppose that as an observer in this world, you see the following retinal image ($\\text{obs}_a$):\n",
    "```\n",
    "▢▢▢▢▢▢■▢▢▢\n",
    "▢▢▢▢▢■▢▢▢▢\n",
    "```  \n",
    "  Calculate the posterior probability of $H1$ and $H2$ and report your results in Moodle.\n",
    "  \n",
    "- b) Suppose in another scenario you have the following retinal image ($\\text{obs}_b$):\n",
    "```\n",
    "▢▢▢▢▢▢■▢▢▢\n",
    "▢▢▢▢▢▢■▢▢▢\n",
    "```  \n",
    "  Calculate the posterior probability of $H1$ and $H2$ and report your results in Moodle.\n",
    "\n",
    "- c) Write out a brief explanation of your reasoning for parts (a) and (b), and report them in Moodle. Add a brief explanation for how your answer to (b) may explain why observers in this world may tend to perceive the second image as containing a *single object*, as opposed to two separate dots. (max 200 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the posterior probabilities we use the Bayes Theorem formula with normalization term equal to the sum of the two hypotheses. The hypothesis probability is already given, the probabilities of the observations given the hypotheses are calculated counting the columns for H1 and multiplying the random positions (since the chance is independent) for H2.\n",
    "\n",
    "The H1 hypothesis has a lower prior probability to happen but given that the likelihood probability is higher the H1 hypothesis is more likely to be true so the observers of this world may really only experience only appearances of vertical columns.  \n",
    "\n",
    "\n",
    "P.S. When answering the quiz I mistakenly filled in with the likelihoods but the code on my notebook is correct. Please consider this in the correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "Write your extended answers here if needed, and report a summary in Moodle (max 200 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answers for part a)\n",
      "\n",
      "posterior_h1: 0.0\n",
      "posterior_h2: 1.0\n",
      "posterior_h1 + posterior_h2: 1.0\n",
      "\n",
      "Answers for part b)\n",
      "\n",
      "posterior_h1: 0.8108108108108109\n",
      "posterior_h2: 0.18918918918918917\n",
      "posterior_h1 + posterior_h2: 1.0\n"
     ]
    }
   ],
   "source": [
    "# code here...\n",
    "ROWS = 2\n",
    "COLS = 10\n",
    "pr_of_h1 = 3/10\n",
    "pr_of_h2 = 7/10\n",
    "\n",
    "# a)\n",
    "print(f\"\"\"\n",
    "Answers for part a)\n",
    "\"\"\")\n",
    "\n",
    "pr_of_h1_observation = 0 / COLS\n",
    "pr_of_h2_observation = 1 / COLS**2\n",
    "\n",
    "posterior_h1 = pr_of_h1_observation * pr_of_h1 / (pr_of_h1_observation * pr_of_h1 + pr_of_h2_observation * pr_of_h2)\n",
    "posterior_h2 = pr_of_h2_observation * pr_of_h2 / (pr_of_h1_observation * pr_of_h1 + pr_of_h2_observation * pr_of_h2)\n",
    "\n",
    "print(f\"posterior_h1: {posterior_h1}\")\n",
    "print(f\"posterior_h2: {posterior_h2}\")\n",
    "print(f\"posterior_h1 + posterior_h2: {posterior_h1 + posterior_h2}\")\n",
    "\n",
    "# b)\n",
    "print(f\"\"\"\n",
    "Answers for part b)\n",
    "\"\"\")\n",
    "      \n",
    "pr_of_h1_observation = 1 / COLS\n",
    "pr_of_h2_observation = 1 / COLS**2\n",
    "\n",
    "posterior_h1 = pr_of_h1_observation * pr_of_h1 / (pr_of_h1_observation * pr_of_h1 + pr_of_h2_observation * pr_of_h2)\n",
    "posterior_h2 = pr_of_h2_observation * pr_of_h2 / (pr_of_h1_observation * pr_of_h1 + pr_of_h2_observation * pr_of_h2)\n",
    "\n",
    "print(f\"posterior_h1: {posterior_h1}\")\n",
    "print(f\"posterior_h2: {posterior_h2}\")\n",
    "print(f\"posterior_h1 + posterior_h2: {posterior_h1 + posterior_h2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.3 (5 pts)\n",
    "\n",
    "> In this question, we examine how an observer would estimate a continuous quantity under a noisy measurement.\n",
    "\n",
    "An observer is estimating the horizontal location of a visual stimulus on a screen (for simplicity, we assume a 1D problem). \n",
    "\n",
    "We assume a Bayesian observer with prior $p(s_\\text{hyp}) = \\mathcal{N}\\left(s| \\mu_s = 2, \\sigma_s^2 = 5^2 \\right)$ and likelihood function $p(x_\\text{obs}| s_\\text{hyp}) = \\mathcal{N}\\left(x_\\text{obs}| s_\\text{hyp}, \\sigma^2 = 2^2 \\right)$ with observed noisy measurement $x_\\text{obs} = -3$, in arbitrary units.\n",
    "\n",
    "- a) What's the value of the posterior mean estimate $\\hat{s}_\\text{PM}$?\n",
    "- b) What's the value of the maximum-likelihood estimate $\\hat{s}_\\text{ML}?$\n",
    "- c) What's the probability density of the posterior at $s_\\text{hyp} = 2.5$?\n",
    "\n",
    "Report your results in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior mean estimate : -2.310344827586207\n",
      "posterior density at s_hyp = 2.5: 0.007498207939080527\n"
     ]
    }
   ],
   "source": [
    "# code here...\n",
    "\n",
    "x_obs = -3\n",
    "prior_mean = 2\n",
    "prior_variance = 5**2\n",
    "\n",
    "likelihood_variance = 2**2\n",
    "\n",
    "post_mean_est = x_obs * ( prior_variance / (prior_variance + likelihood_variance)) + prior_mean * (likelihood_variance / (prior_variance + likelihood_variance) )\n",
    "\n",
    "print(f\"posterior mean estimate : {post_mean_est}\")\n",
    "\n",
    "post_variance_est = (prior_variance * likelihood_variance) / (prior_variance + likelihood_variance)\n",
    "\n",
    "s_hyp = 2.5\n",
    "posterior_density = sps.norm.pdf(s_hyp, loc=post_mean_est, scale=np.sqrt(post_variance_est))\n",
    "print(f\"posterior density at s_hyp = 2.5: {posterior_density}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1.4 (5 pts)\n",
    "\n",
    "> In this question, we examine a more complex inference scenario under a noisy measurement and a complex prior.\n",
    "\n",
    "\n",
    "A Bayesian observer is estimating the value of a stimulus (e.g., horizontal location of a sound source, in arbitrary units).\n",
    "The observer is told that there are two potential sound sources (e.g., two speakers hidden behind a screen), one to the right and one to the left (0 is straight ahead), but the observer is not told the exact location of these sound sources, just a vague position.\n",
    "\n",
    "Thus, we represent the observer's prior over the potential sound location as a mixture of $K = 2$ Gaussians:\n",
    "$$p(s_\\text{hyp}) = \\sum_{k=1}^K w_k \\mathcal{N}\\left(s_\\text{hyp}| \\mu_k, \\sigma_k^2\\right)$$\n",
    "where \n",
    "$$w_1 = w_2 = \\frac{1}{2}, \\qquad \\mu_1 = -3, \\mu_2 = 3, \\qquad \\sigma_1 = \\sigma_2 = 1.$$\n",
    "Each mixture component represents one of the two potential locations of the sound (each component is Gaussian, and not a single point, because the location of the source itself is not exactly known).\n",
    "\n",
    "After the sound is played (heard as noisy measurement $x_\\text{obs}$), the likelihood is Gaussian, $p(x_\\text{obs}| s_\\text{hyp}) = \\mathcal{N}\\left(x_\\text{obs}| s_\\text{hyp}, \\sigma^2 \\right)$, with $\\sigma = 1$.\n",
    "\n",
    "- a) Compute the posterior mean for $x_\\text{obs} = 1$ via numerical integration.\n",
    "- b) Compute $p(x_\\text{obs})$ for $x_\\text{obs} = 5$ via numerical integration.\n",
    "- c) Given that the prior is a mixture of Gaussians and the likelihood is Gaussian, this is a case in which we could still perform all computations analytically. Write the analytical expression for $p(x_\\text{obs})$. Double-check the validity of your expression by computing $p(x_\\text{obs})$ for $x_\\text{obs} = 5$ and that it is the same (up to a small numerical error) as what you got in part (b).\n",
    "\n",
    "Report your numerial results in Moodle, and write the analytical expression for $p\\left(x_\\text{obs}\\right)$ below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(x_\\text{obs}) = \\frac{1}{2}\\mathcal{N}\\left(x_\\text{obs}| \\mu_1, \\sigma_1^2+\\sigma^2\\right) + \\frac{1}{2}\\mathcal{N}\\left(x_\\text{obs}| \\mu_2, \\sigma_2^2+\\sigma^2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "Write your expression for $p(x_\\text{obs})$ here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior mean for x_obs = 1: 1.857722380467301\n",
      "p(x_obs) for x_obs = 5: 0.05188845305036771\n"
     ]
    }
   ],
   "source": [
    "# code here...\n",
    "w1 = w2 = 0.5\n",
    "mean_1, mean_2 = -3, 3\n",
    "var_1 = var_2 = 1\n",
    "likelihood_var = 1\n",
    "\n",
    "def prior(s):\n",
    "    return w1 * sps.norm.pdf(s, mean_1, var_1) + w2 * sps.norm.pdf(s, mean_2, var_2)\n",
    "\n",
    "def likelihood(x_obs, s):\n",
    "    return sps.norm.pdf(x_obs, s, likelihood_var)\n",
    "\n",
    "def posterior( s, x_obs ):\n",
    "    return prior(s) * likelihood(x_obs, s)\n",
    "\n",
    "posterior_mean = sp.integrate.quad(lambda s: s * posterior(s, 1), -np.inf, np.inf)[0] / sp.integrate.quad(lambda s: posterior(s, 1), -np.inf, np.inf)[0]\n",
    "prob_x_obs, _ = sp.integrate.quad(lambda s: posterior(s, 5), -np.inf, np.inf)\n",
    "\n",
    "print(f\"posterior mean for x_obs = 1: {posterior_mean}\")\n",
    "print(f\"p(x_obs) for x_obs = 5: {prob_x_obs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
